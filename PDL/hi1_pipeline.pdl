#-*-perl-*-
use strict;

=head2 hi1_pipeline - invoke the background-subtraction pipeline on a single batch of hi1 data.

=for usage
     
     $out = hi1_pipeline( $in_list, $opt );

=for ref

Accepts a list of FITS files, generates a collection of FITS files in a specified output
directory.  This is the central logic to process a single batch of FITS files.  For true pipeline
use you need to run several staggered batches and then merge the output with C<merge_batches>.
If you want to run a specific predefined STEREO/HI batch, use hi1_pipeline_batch, which accepts a 
batch number and searches for the appropriate files in the L1 data store on your system.

If you specify no options at all, a reasonable set of defaults are applied.  All of the subfilters
accept options that are passed-through in the options hash.  See the documentation for the individual 
filters for their options.

Options accepted and acted on by hi1_pipeline itself are:

=over 3

=item OUTPUT_DIR (default 'processed') - the name of the directory where processed files should go

=item OUTPUT_FILES (default 1) - a flag: whether to generate output files

=item KEEP_DATA (default 0) - a flag: whether intermediate data sets should be retained in the working hash

=item KEEP_NULLED (default 1) - a flag: whether to keep (and save) NULLED data as well as fully processed.

=back

The steps applied are:

=over 3

=item C<read_files>

This creates the working hash data structure and reads in the files from the file list, filtering out suspicious
ones.

=item C<remove_f_corona>

This, er, removes F corona (specifically, a baseline minimum value)
from the images

=item C<get_distortion_params2>

This extracts the distortion function from the starfield

=item C<shift_to_celestial>

This shifts the images to celestial coordinates, including dejittering.

=item C<null_stars>

This attempts to null out the starfield using the minimum value in the
celestial plane

=item C<clean_telegraph>

This removes residual starfield effects that are due to nonlinearities
in the HI detector; these yield slight flickering in the remaining stars.

=item C<motion_filter>

This removes residual second-order artifacts from the F corona process and
starfield nulling.

=item C<null_stars> (2nd iteration)

This is re-establishes the same minimum scheme as for before the
motion filtering.

=item C<shift_to_instrument>

Resamples back to instrument coordinates.  The jitter correction from 
earlier is not reapplied.

=back

=cut
$PDL::BIGPDL = 1;
use Date::Format;

sub hi1_pipeline {
    my $in_list = shift;
    my $opt = shift;
    my $VERSION = "2.1 (21-May-2013)";
    my $i;

    my $opt_defaults = {

	OUTPUT_DIR		=> 'processed', # where to put output files
	OUTPUT_FILES		=> 1,           # Whether to generate output
	KEEP_DATA               => 0,           # Whether to keep (and return) the data cubes
	KEEP_NULLED             => 1,           # Whether to keep the stellar nulled data as well as motion-filtered.

	pct			=> 2,     # 2% for F corona - could be smaller maybe, but works OK
	sm                      => 0,     # No smoothing at the remove_f_corona stage
	bin			=> 0,     # don't bother rebinning 2k x 2k images - just reject them
	REMOVE_FLUCTUATIONS	=> 1,     # Do remove exposure fluctuations
	MASK_RADIUS             => 0,     # No radial masking
	MARK_BAD                => 0,     # Don't bother marking bad elements
	BAD_DIL_FR              => 0,     # Items marked bad should not be dilated across frames
	BAD_DIL_PIX             => 1.5,   # Dilate spatially by +/- 1.5 pixel (3 total)

	DIST_CORRTIME           => 3,       # Use 3-day correlation
	DIST_CORR_NSAMP		=> 40,      # 40 x 40 samples
	DIST_CORR_RSIZE         => 35,      # 35 pixel radius for guesses
	DIST_CORR_PSIZE         => 35,      # 35 pixel radius patch size for final correlation
	DIST_GUESS_DRIFTRATE    => 260/5,   # Initial guess is 260 pixels in 5 days

	NULL_MIN_PCT		=> 1,      # Null stars to the 3rd percentile
	NULL_SMOOTH_SIZE	=> [3,3],  # Smooth 3x3 pixels with a median filter.
	NULL_SMOOTH_FRAMES      => 1,      # Actually do the smoothing
	NULL_UNSHARP_FILTER     => 6,      # Radius for the unsharp-filter mask used to find residual spikes
	
	INTERP_METHOD           => 'h',    # Use hanning-window interpolation instead of pure Gaussian.

	ALIGN_DEJITTER          => 1,      # Dejitter by correlating frames during resampling to celestial coords

	TELEGRAPH_US_SIZE       => 9,      # Diameter of unsharp mask in telegraph step
	TELEGRAPH_MASK_TRIGGER  => 3,      # Anything more than 3x the local smoothed RMS value is a telegraph pixel
	TELEGRAPH_SPIKE_TRIGGER => 1e-13,  # Anything larger than this in the unsharp-masked image is bad
	TELEGRAPH_DIL_FR        => 2,      # Dilate bad values +/- this many frames
	
	MOTION_FILTER           => 1,      # Carry out motion filtering
	FILTER_APOD_FRAMES      => 5,      # Apodize by 5 frames
	FILTER_APOD_MARGIN      => 40,     # Apodize edges by 40 pixels
	FILTER_MAX_SIZE         => 30,     # Allow objects larger than 30 pixels to persist even if not moving
	FILTER_US_SIZE		=> 11,     # Unsharp-mask size for the badmask
	FILTER_DIL_SIZE         => 3,      # Dilate bad values +/- this many pixels
	FILTER_SLOP             => 0.5,    # Very smooth motion filter cutoff to minimize ringing
	FILTER_CUTOFF_PPF       => 1,      # Anything slower than one pixel per frame gets nixed
	FILTER_HYPERSMOOTHING   => 15,     # Hypersmooth the background
	FILTER_REMOVE_FIXED     => 0,      # Don't remove the fixed component
	FILTER_ZAP_HF           => 0,      # Don't truncate the high wavevector corners of the Brillouin zone

	PIXEL_XRANGE            => pdl(2,1022),
	PIXEL_YRANGE            => pdl(2,1022),
	DEBUG_PIPELINE          => 0,
	DEBUG_OUTPUT_PREFIX     => "tmp/",
	CLEAN_MARGIN_FRAMES     => 2,

    };

    my $k;
    for $k(keys %$opt_defaults) {
	$opt->{$k} = $opt_defaults->{$k} unless(exists($opt->{$k}));
    }

    our $hash;

    ##############################
    # Read and filter files, and create the working hash.
    $hash = read_files($in_list,$opt);

    # Remove the F corona
    remove_f_corona($hash,$opt);

    delete $hash->{RAW_CUBE} unless($opt->{KEEP_DATA});

    # Map starfield distortion for the batch
    print "distortion parameters...\n";
    get_distortion_params2($hash, $opt);   # measure stellar drift

    # Resample to celestial coordinates
    print "shift_to_celestial...\n";
    shift_to_celestial($hash, $opt);      # nullify stellar drift

    delete $hash->{BKSUB_CUBE} unless($opt->{KEEP_DATA});

    # Null out the starfield
    print "null_stars...\n";
    null_stars($hash, $opt);              # try to cancel out the starfield

    my $datestr = time2str("%Y-%m-%dT%H:%M:%SZ",time,"Z");

    if($opt->{KEEP_NULLED}) {
	local($hash->{log});
	print "Shift nulled data to instrument coords...\n";

	shift_to_instrument($hash,$opt);

	$hash->{NULLED_CUBE} = $hash->{CLEAN_CUBE};
	delete $hash->{CLEAN_CUBE};
	$hash->{NULLED_log} = [@{$hash->{log}}];

	if($opt->{OUTPUT_FILES}) {
	    `mkdir $opt->{OUTPUT_DIR}-S`;
	    for $i(0..$hash->{NULLED_CUBE}->dim(2)-1) {
		my $im = $hash->{NULLED_CUBE}->(:,:,($i));
		
		# Deep copy the FITS header to save the contents for later...
		my $hdr = new Astro::FITS::Header( Cards => [(tied %{$hash->{RAW_HDRS}->[$i]})->cards] );
		my %hdrhash;
		tie %hdrhash, "Astro::FITS::Header", $hdr;
		$im->sethdr(\%hdrhash);
		
		$im->hdr->{DATE} = $datestr;
		$im->hdr->{DATE_COMMENT} = "Pipeline time";
		$im->hdr->{HISTORY} .= "Processed with SwRI HI_1 pipeline $VERSION. Filters:\n";
		for(@{$hash->{log}}) {$im->hdr->{HISTORY} .= $_."\n"}
		$im->hdr->{FILENAME} =~ s/_1(....\.fts)$/_2S$1/;
		$im->hdr->{ORIGIN} = "SwRI / postprocessing only";
		$im->hdr->{COMMENT} .= "Starfield nulled using SwRI batch processing (some artifacts may remain)";
		$im->hdr->{COMMENT} .= "** This is a batch file intended to be merged with others **";
		
		my $fname = sprintf("%s-S/S-clean-%s--BATCH-%s.fits",
				    $opt->{OUTPUT_DIR}, 
				    $im->hdr->{'DATE-OBS'},
				    $hash->{RAW_HDRS}->[0]->{'DATE-OBS'}
		    );
		printf("Writing %d of %d: %s\n",$i,$hash->{NULLED_CUBE}->dim(2)-1, $fname );
		wfits($im, $fname);
	    }
	}

	delete $hash->{NULLED_CUBE} unless($opt->{KEEP_DATA});
    }

    ##############################
    # Attempt to find and remove telegraph pixels (stars/planets)
    print "Clean telegraph...\n";
    clean_telegraph($hash,$opt);

    ##############################
    # Apply the motion filter
    print "Motion filter...\n"; 
    motion_filter($hash,$opt);
    
    ##############################
    # Re-null to establish the zero point
    print "Second null...\n";
    null_stars($hash,$opt);

    ##############################
    # Shift back to instrument coordinates.
    print "Shift back to instrument...\n";
    shift_to_instrument($hash,$opt);

    # Dump output to files...
    if($opt->{OUTPUT_FILES}) {
        `mkdir $opt->{OUTPUT_DIR}-M`;
	for $i($opt->{CLEAN_MARGIN_FRAMES}..$hash->{CLEAN_CUBE}->dim(2)-1-$opt->{CLEAN_MARGIN_FRAMES}) {
	    my $im = $hash->{CLEAN_CUBE}->(:,:,($i))->copy;

	    $im->sethdr($hash->{RAW_HDRS}->[$i]);
	    $im->hdr->{DATE} = $datestr;
	    $im->hdr->{DATE_COMMENT} = "Pipeline time";
	    $im->hdr->{HISTORY} .= "Processed with SwRI HI_1 pipeline $VERSION. Filters:\n";
	    for(@{$hash->{log}}) {$im->hdr->{HISTORY} .= $_."\n"}
	    $im->hdr->{FILENAME} =~ s/_1(....\.fts)$/_2S$1/;
	    $im->hdr->{ORIGIN} = "SwRI / postprocessing only";
	    $im->hdr->{COMMENT} .= "Motion-filtered using SwRI batch processing (some artifacts may remain)";
	    $im->hdr->{COMMENT} .= "** This is a batch file intended to be merged with others **";

	    my $fname = sprintf ("%s-M/M-clean-%s--BATCH-%s.fits", 
				 $opt->{OUTPUT_DIR}, 
				 $im->hdr->{'DATE-OBS'}, 
				 $hash->{RAW_HDRS}->[0]->{'DATE-OBS'}
		);

	    printf("Writing file %d of %d: %s\n",  $i,  $hash->{CLEAN_CUBE}->dim(2) - 1,  $fname);
	    wfits($im, $fname);
	}
    }
    print "Returning...\n";
}
